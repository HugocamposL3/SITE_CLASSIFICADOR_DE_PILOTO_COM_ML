{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resultados_df = pd.read_csv('/kaggle/input/formula-1-world-championship-1950-2020/results.csv')\ncorridas_df = pd.read_csv('/kaggle/input/formula-1-world-championship-1950-2020/races.csv')\npilotos_df = pd.read_csv('/kaggle/input/formula-1-world-championship-1950-2020/drivers.csv')\nconstrutores_df = pd.read_csv('/kaggle/input/formula-1-world-championship-1950-2020/constructors.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con1 = pd.merge(resultados_df, corridas_df,how = 'left', on ='raceId')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con1 = con1.drop(['url','fp1_date', 'fp1_time', 'fp2_date', 'fp2_time','date','time_y','time_x',\n              'fp3_date', 'fp3_time', 'quali_date', 'quali_time', 'sprint_date','sprint_time','round',],1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con2 = pd.merge(con1, pilotos_df, on = 'driverId')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con2 = con2.drop(['fastestLap','fastestLapTime','fastestLapSpeed','code'],1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con2.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con2 = con2.drop(['dob','nationality','url','number_y'],1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con2 = con2.drop(['milliseconds','driverRef','laps','resultId','number_x','positionText', 'positionOrder','raceId','driverId', 'grid', 'position',\n                 'rank', 'statusId','circuitId'],1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con2['driver_name'] = con2['forename']+' '+con2['surname']\ncon2 = con2.drop(['forename','surname'],1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con2008 = con2[con2['year']==2008]\ncon2008.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pointsdriver = con2008.groupby('driver_name')['points'].sum()\nprint(pointsdriver)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con2008 = pd.merge(con2008, pointsdriver,how = 'left', on ='driver_name')\ncon2008.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con2008['classificacao']=con2008['points_y'].rank(ascending=False,method='dense')\ncon2008.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con2000 = con2[con2['year']==2000]\npointsdriver = con2000.groupby('driver_name')['points'].sum()\ncon2000 = pd.merge(con2000, pointsdriver,how = 'left', on ='driver_name')\ncon2000['classificacao']=con2000['points_y'].rank(ascending=False,method='dense')\n\ncon2001 = con2[con2['year']==2001]\npointsdriver = con2001.groupby('driver_name')['points'].sum()\ncon2001 = pd.merge(con2001, pointsdriver,how = 'left', on ='driver_name')\ncon2001['classificacao']=con2001['points_y'].rank(ascending=False,method='dense')\n\ncon2002 = con2[con2['year']==2002]\npointsdriver = con2002.groupby('driver_name')['points'].sum()\ncon2002 = pd.merge(con2002, pointsdriver,how = 'left', on ='driver_name')\ncon2002['classificacao']=con2002['points_y'].rank(ascending=False,method='dense')\n\ncon2003 = con2[con2['year']==2003]\npointsdriver = con2003.groupby('driver_name')['points'].sum()\ncon2003 = pd.merge(con2003, pointsdriver,how = 'left', on ='driver_name')\ncon2003['classificacao']=con2003['points_y'].rank(ascending=False,method='dense')\n\ncon2004 = con2[con2['year']==2004]\npointsdriver = con2004.groupby('driver_name')['points'].sum()\ncon2004 = pd.merge(con2004, pointsdriver,how = 'left', on ='driver_name')\ncon2004['classificacao']=con2004['points_y'].rank(ascending=False,method='dense')\n\ncon2005 = con2[con2['year']==2005]\npointsdriver = con2005.groupby('driver_name')['points'].sum()\ncon2005 = pd.merge(con2005, pointsdriver,how = 'left', on ='driver_name')\ncon2005['classificacao']=con2005['points_y'].rank(ascending=False,method='dense')\n\ncon2006 = con2[con2['year']==2006]\npointsdriver = con2006.groupby('driver_name')['points'].sum()\ncon2006 = pd.merge(con2006, pointsdriver,how = 'left', on ='driver_name')\ncon2006['classificacao']=con2006['points_y'].rank(ascending=False,method='dense')\n\ncon2007 = con2[con2['year']==2007]\npointsdriver = con2007.groupby('driver_name')['points'].sum()\ncon2007 = pd.merge(con2007, pointsdriver,how = 'left', on ='driver_name')\ncon2007['classificacao']=con2007['points_y'].rank(ascending=False,method='dense')\n\ncon2009 = con2[con2['year']==2009]\npointsdriver = con2009.groupby('driver_name')['points'].sum()\ncon2009 = pd.merge(con2009, pointsdriver,how = 'left', on ='driver_name')\ncon2009['classificacao']=con2009['points_y'].rank(ascending=False,method='dense')\n\ncon2010 = con2[con2['year']==2010]\npointsdriver = con2010.groupby('driver_name')['points'].sum()\ncon2010 = pd.merge(con2010, pointsdriver,how = 'left', on ='driver_name')\ncon2010['classificacao']=con2010['points_y'].rank(ascending=False,method='dense')\n\ncon2011 = con2[con2['year']==2011]\npointsdriver = con2011.groupby('driver_name')['points'].sum()\ncon2011 = pd.merge(con2011, pointsdriver,how = 'left', on ='driver_name')\ncon2011['classificacao']=con2011['points_y'].rank(ascending=False,method='dense')\n\ncon2012 = con2[con2['year']==2012]\npointsdriver = con2012.groupby('driver_name')['points'].sum()\ncon2012 = pd.merge(con2012, pointsdriver,how = 'left', on ='driver_name')\ncon2012['classificacao']=con2012['points_y'].rank(ascending=False,method='dense')\n\ncon2013 = con2[con2['year']==2013]\npointsdriver = con2013.groupby('driver_name')['points'].sum()\ncon2013 = pd.merge(con2013, pointsdriver,how = 'left', on ='driver_name')\ncon2013['classificacao']=con2013['points_y'].rank(ascending=False,method='dense')\n\ncon2014 = con2[con2['year']==2014]\npointsdriver = con2014.groupby('driver_name')['points'].sum()\ncon2014 = pd.merge(con2014, pointsdriver,how = 'left', on ='driver_name')\ncon2014['classificacao']=con2014['points_y'].rank(ascending=False,method='dense')\n\ncon2015 = con2[con2['year']==2015]\npointsdriver = con2015.groupby('driver_name')['points'].sum()\ncon2015 = pd.merge(con2015, pointsdriver,how = 'left', on ='driver_name')\ncon2015['classificacao']=con2015['points_y'].rank(ascending=False,method='dense')\n\ncon2016 = con2[con2['year']==2016]\npointsdriver = con2016.groupby('driver_name')['points'].sum()\ncon2016 = pd.merge(con2016, pointsdriver,how = 'left', on ='driver_name')\ncon2016['classificacao']=con2016['points_y'].rank(ascending=False,method='dense')\n\ncon2017 = con2[con2['year']==2017]\npointsdriver = con2017.groupby('driver_name')['points'].sum()\ncon2017 = pd.merge(con2017, pointsdriver,how = 'left', on ='driver_name')\ncon2017['classificacao']=con2017['points_y'].rank(ascending=False,method='dense')\n\ncon2018 = con2[con2['year']==2018]\npointsdriver = con2018.groupby('driver_name')['points'].sum()\ncon2018 = pd.merge(con2018, pointsdriver,how = 'left', on ='driver_name')\ncon2018['classificacao']=con2018['points_y'].rank(ascending=False,method='dense')\n\ncon2019 = con2[con2['year']==2019]\npointsdriver = con2019.groupby('driver_name')['points'].sum()\ncon2019 = pd.merge(con2019, pointsdriver,how = 'left', on ='driver_name')\ncon2019['classificacao']=con2019['points_y'].rank(ascending=False,method='dense')\n\ncon2020 = con2[con2['year']==2020]\npointsdriver = con2020.groupby('driver_name')['points'].sum()\ncon2020 = pd.merge(con2020, pointsdriver,how = 'left', on ='driver_name')\ncon2020['classificacao']=con2020['points_y'].rank(ascending=False,method='dense')\n\ncon2021 = con2[con2['year']==2021]\npointsdriver = con2021.groupby('driver_name')['points'].sum()\ncon2021 = pd.merge(con2021, pointsdriver,how = 'left', on ='driver_name')\ncon2021['classificacao']=con2021['points_y'].rank(ascending=False,method='dense')\n\ncon2022 = con2[con2['year']==2022]\npointsdriver = con2022.groupby('driver_name')['points'].sum()\ncon2022 = pd.merge(con2022, pointsdriver,how = 'left', on ='driver_name')\ncon2022['classificacao']=con2022['points_y'].rank(ascending=False,method='dense')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mika = con2000.loc[con2000['driver_name']=='Mika Häkkinen']\nmika.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fernando = con2005.loc[con2005['driver_name']=='Fernando Alonso']\nfernando.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"contotal = pd.concat([con2000,con2001,con2002,con2003,con2004,con2005,con2005,con2006,con2007,con2008,con2009,con2010,con2011,con2012,con2013,con2014,con2015,con2016,con2017,con2018,\n                           con2019,con2020,con2021,con2022])\ncontotal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.merge(contotal,construtores_df,how = 'left', on ='constructorId')\ndf.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['constructorId','points_x','name_x','points_y','constructorRef','nationality','url'],1)\ndf = df.rename(columns={'name_y':'constructor_name','classificacao':'classification'})\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum() / len(df) * 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split \nimport warnings \nwarnings.simplefilter('ignore')\npd.set_option('display.max_columns',None)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nsns.heatmap(df.corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# separando colunas categóricas e numéricas para compreensão\ncat = []\nnum = []\nfor i in df.columns:\n    if df[i].dtypes == 'O':\n        cat.append(i)\n    else:\n        num.append(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[cat].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[num].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder \nle = LabelEncoder()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# codificação de colunas categóricas\nfor i in cat:\n    df[i] = le.fit_transform(df[i])\ndf.head(30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nsns.heatmap(df.corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df.drop('classification',1)\ny = df.classification","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nxtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.3,random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing ML libraries \n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn import tree","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = DecisionTreeClassifier (max_depth=5,random_state=1234)\nclf.fit(xtrain,ytrain)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree.export_text(clf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fn = list(df.columns)\nfn.remove(\"classification\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(80,80))\n_ = tree.plot_tree(clf,feature_names = fn, filled=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression (solver='sag')\ndt = DecisionTreeClassifier()\nrn = RandomForestClassifier()\nknn = KNeighborsClassifier()\ngb = GaussianNB()\nsgd = SGDClassifier()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"li = [lr,sgd,knn,gb,rn,dt]\nd = {}\nfor i in li:\n    i.fit(xtrain,ytrain)\n    ypred = i.predict(xtest)\n    print(i,\":\",accuracy_score(ypred,ytest)*100)\n    d.update({str(i):i.score(xtest,ytest)*100})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 7.5))\nplt.title(\"Algorithm vs Accuracy\", fontweight='bold')\nplt.xlabel(\"Algorithm\")\nplt.ylabel(\"Accuracy\")\nplt.plot(d.keys(),d.values(),marker='o',color='plum',linewidth=4,markersize=13,\n         markerfacecolor='gold',markeredgecolor='slategray')\nfor x,y in zip(d.keys(),d.values()):\n    label = \"{:.2f}\".format(y)\n    plt.annotate(label,(x,y),textcoords=\"offset points\",xytext=(-3.75,5),ha='right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nprint(\"Acurácia: \", accuracy_score(ytest, ypred))\nprint(\"Precisão: \", precision_score(ytest, ypred, average='macro'))\nprint(\"Recall: \", recall_score(ytest, ypred, average='macro'))\nprint(\"F1-score: \", f1_score(ytest, ypred, average='macro'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exportando o modelo final para implantação\nimport pickle\n\npickle.dump(dt, open('/kaggle/working/models2.pkl', 'wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\ny_train_pred = rn.predict(xtrain)\ny_test_pred = rn.predict(xtest)\ntrain_accuracy = accuracy_score(ytrain, y_train_pred)\ntest_accuracy = accuracy_score(ytest, y_test_pred)\n# Imprimir a precisão nos dados de treinamento e teste\nprint(\"Precisão nos dados de treinamento: {:.2f}\".format(train_accuracy))\nprint(\"Precisão nos dados de teste: {:.2f}\".format(test_accuracy))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}